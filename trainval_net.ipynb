{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train FPN')\n",
    "    parser.add_argument('--dataset', dest='dataset',\n",
    "                        help='training dataset',\n",
    "                        default='pascal_voc', type=str)\n",
    "    parser.add_argument('--net', dest='net',\n",
    "                        help='res101, res152, etc',\n",
    "                        default='res101', type=str)\n",
    "    parser.add_argument('--start_epoch', dest='start_epoch',\n",
    "                        help='starting epoch',\n",
    "                        default=1, type=int)\n",
    "    parser.add_argument('--num_epochs', dest='num_epochs',\n",
    "                        help='number of epochs to train',\n",
    "                        default=20, type=int)\n",
    "    parser.add_argument('--display_interval', dest='display_interval',\n",
    "                        help='number of iterations to display',\n",
    "                        default=100, type=int)\n",
    "    parser.add_argument('--checkpoint_interval', dest='checkpoint_interval',\n",
    "                        help='number of iterations to create checkpoint',\n",
    "                        default=10000, type=int)\n",
    "    \n",
    "    parser.add_argument('--save_dir', dest='save_dir',\n",
    "                        help='directory to save models',\n",
    "                        default='', nargs=argparse.REMAINDER)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "  def __init__(self, train_size, batch_size):\n",
    "    num_data = train_size\n",
    "    self.num_per_batch = int(num_data / batch_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "    self.leftover_flag = False\n",
    "    if num_data % batch_size:\n",
    "      self.leftover = torch.arange(self.num_per_batch*batch_size, num_data).long()\n",
    "      self.leftover_flag = True\n",
    "  def __iter__(self):\n",
    "    rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "    self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "    self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "    if self.leftover_flag:\n",
    "      self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "    return iter(self.rand_num_view)\n",
    "\n",
    "  def __len__(self):\n",
    "    return num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset `voc_2012_trainval` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "done\n",
      "Preparing training data...\n",
      "wrote gt roidb to /workspaces/FPN-with-Pytorch/datasets/cache/voc_2012_trainval_gt_roidb.pkl\n",
      "done\n",
      "before filtering, there are 0 images...\n",
      "after filtering, there are 0 images...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # args = parse_args()\n",
    "\n",
    "    # print('Called with args:')\n",
    "    # print(args)\n",
    "    imdb, roidb, ratio_list, ratio_index = combined_roidb('voc_2012_trainval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.pascal_voc.pascal_voc at 0x7e1ae0137df0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
